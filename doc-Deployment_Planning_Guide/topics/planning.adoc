[[planning]]
== Planning

This guide provides some general guidelines to planning a deployment on {product-title}. This includes creating multiple regions containing {product-title} appliances, CPU sizing recommendations, database sizing recommendations, and database configuration.

[[regions]]
=== Regions

Regions are used for centralizing data which is collected from public and private virtualization environments. A region is ultimately represented as a single database for the VMDB. Regions are particularly useful when multiple geographical locations need to be managed, as they enable all the data collection to happen at each particular location and avoid data collection traffic across slow links between networks.

When multiple regions are being used, each with their own unique ID, a master region can be created to centralize the data of all the children regions into a single master database. To do this, configure each child region to replicate its data to the master region database (Red Hat recommends use of region 99, though any number up to three digits will work). This parent and child region is a one-to-many relationship.

Regions can contain multiple zones, which in turn contain appliances. Zones are used for further segregating network traffic along with enabling failover configurations. Each appliance has the capability to be configured for a number of specialized server roles. These roles are limited to the zone containing the appliance they run on.

Only one failover type of each server role can run in a zone. If multiple appliances have the same failover role, the extras are used as backups that activate only if the primary appliance fails. Non-failover server roles can run on multiple appliances simultaneously in a zone, so resources can be adjusted according to the workload those roles are responsible for.

The following diagram demonstrates an example of the multiple regions working together in a {product-title} environment.

image:7151.png[]

The Master appliance is located in Chicago and contains a master region and a subregion that manages the worker appliances. The Mahwah technology center contains a single subregion that manages two zones.
Likewise, the San Diego technology center contains a single subregion managing a single zone.

[NOTE]
====
* Replicating a parent region to a higher-level parent is not supported.
* Parent regions can be configured after the child regions are online.
====

The following diagram provides a closer look at a region:

image:7150.png[]

In this region, we have several {product-title} appliances acting as UI nodes and worker nodes. These worker nodes execute tasks on the providers in your environment.
The Region also uses a region database that reports to a master database on the main {product-title} appliance. All appliances can connect to the authentication services (Active Directory, LDAP, Identity Management), outgoing mail (SMTP), and network services (SNMP).


[NOTE]
====
{product-title} can be configured in a highly available setup. In this case, all PostgreSQL instances must be running on a server that is deployed from the {product-title} appliance. 
ifdef::cfme[]
For more information, see the following example reference architecture:
https://access.redhat.com/articles/1571263[Implementing Highly Available CloudForms Appliances]. Note, this reference architecture was written for a previous version of CloudForms.
endif::cfme[]
====

[[central-administration]]
=== Centralized Administration

{product-title} includes centralized administration capabilities, where operations can be initiated from the global region and processed and executed on the remote region. This includes the following life cycle management operations:

* Virtual machine provisioning
* Service provisioning
* Virtual machine power operations
* Virtual machine retirement
* Virtual machine reconfiguration

image:centralized_admin.png[Centralized Administration Diagram]

With centralized administration, the remote_queue_put leverages a new system-to-system REST API request to forward the original request to the remote region. This request is put in the local queue in the remote region, which is then delivered by a worker in the remote region as if it was queued there all along. As a result, a {product-title_short} operator in the global region can be seen as provisioning on behalf of a remote region. 

[NOTE]
====
The operations initiated from the global region are subject to the role-based access control (RBAC) rules on the remote region. The user in the remote region which matches the logged-in user's *user ID* will be used to enforce RBAC in the target region. The operation will fail on the remote system if the user does not have the required permissions. 
====

For information on how to configure centralized administration via database replication, see the section on _Configuring Database Replication and Centralized Administration_ in the https://access.redhat.com/documentation/en/red-hat-cloudforms/4.2/single/general-configuration/[General Configuration] guide.

[[tenants]]
=== Tenancy

{product-title} supports multitenancy, letting you isolate one tenant’s resources and user accounts from another. It allows you to create and manage siloed organizations that have separate authentication and users, different branding, and different security settings. 

Tenants can be totally separate or they can be in a parent-child or peer relationship. Tenants in a relationship can share or inherit a certain configuration. You can subdivide and create child tenants and they, in turn, can have child tenants, and so on. The ability to have multi-level (nested) tenants in a hierarchy enables those at the bottom to inherit permissions from those above. This configuration allows for granular user permissions to be set on specific tenants.  

A tenant can also contain a self-contained child tenant known as a 'project'. A project cannot have a child tenant, but is useful for allocating resources to a small group or team within a larger organization.

[NOTE]
====
If you do not add any additional tenants, all resources and user accounts are contained in a single base tenant which is your {product-title_short} appliance itself. In {product-title_short}, is sometimes referred as 'tenant zero'.
====

Tenancy Account Roles::

In {product-title_short}, the following two account roles are associated with tenancy:
 
* Tenant administrator
* Tenant quota administrator

ifdef::cfme[]
See https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/general_configuration/#roles[Account Roles and Descriptions] in the _General Configuration_ guide for more information about these roles.
endif::cfme[]

[IMPORTANT]
====
Tenant administrator and tenant quota administrator roles are like administrator and super administrator. These roles are not limited to the tenant upon which they are acting and act across all tenants, and therefore should be considered privileged users. These are not roles inside a tenant.
====

Tenancy Models::

The following two approaches exist for tenancy planning:

* *Tenantless* - You can create a single large tenant, sometimes referred as 'tenant zero', and perform all your operations in there without any subdivision of resources or user accounts.
* *Enterprise model* - A common scenario is to create a single tenant, and then subdivide it based on the structures or departments within your organization. Those departments are then able to further subdivide their resources into distinct projects. With this model, you have a single URL for user access, while still having the ability to divide resources into nested hierarchical tenants.

Tenancy Configuration::

You can create and configure tenancy using the {product-title_short} user interface in the same place you set up users, groups and roles by selecting *Configuration* from the settings menu, and then clicking on the *Access Control* accordion. 
ifdef::cfme[] 
See the section on https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/general_configuration/#access-control[Access Control] in the _General Configuration_ guide for procedures on how to create tenants and projects, users, and groups. 
endif::cfme[]

Tenancy in Automation::

One of the features of tenancy is that each tenant can have its own automate domain. Tenant-based domains can help in several use cases, such as if you have:

• groups that need their own naming routines
• varying types of approval needs
• departments that use different end ticketing systems
• a customer who is a holding company or centralized IT organization for managing different business units

Just like standard domains are nested, you can also add automate domains that are nested at the tenant level. 
ifdef::cfme[] 
For the procedure on how to create a new automate domain, see https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/scripting_actions_in_cloudforms/[Scripting Actions in CloudForms]. 
endif::cfme[]

Tenancy Quota and Reporting::

You can allocate and enforce quotas for the following attributes:

* Virtual CPUs
* Memory in GB
* Storage in GB
* Number of virtual machines
* Number of templates

ifdef::cfme[]
See the section on https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/general_configuration/#access-control[Managing Tenant and Project Quotas] in the _General Configuration_ guide for procedures on how to create and manage quotas.
endif::cfme[]

You can generate or schedule a report for *Tenant Quotas* similar to other reports.
ifdef::cfme[]
See https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/monitoring_alerts_and_reporting/#sect_reports[Reports] in the _Monitoring, Alerts, and Reporting_ guide for procedures on how to view or schedule a report.
endif::cfme[] 

The following example shows a tenant quota report:

image:tenant-quotas-report.png[]

* Total Quota: Total quota enforced per attribute for a tenant
* In Use: Amount of quota currently in use by tenants
* Allocated: Amount of quota given to all child tenants
* Available: _Total Quota_ minus (-) _In Use_ minus (-) _Allocated_


Tenancy Chargeback::

You have the ability to do tenancy in chargeback where you are able to assign rates and have a different rate for each tenant. You can make use of the default rate or create your own set of rates depending on the tenant. As well, there is an ability to create chargeback reports by tenant. 

ifdef::cfme[]
See https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/monitoring_alerts_and_reporting/#sect_chargeback[Chargeback] in the _Monitoring Alerts, and Reporting_ guide for information on how to create and assign default or custom chargeback rates, and how {product-title_short} calculates chargeback costs. 
endif::cfme[]

Tenancy Service Catalogs::

Similar to automate domains, you can have service catalogs at each level of tenancy. Once you add a service catalog at a particular level of tenancy, it is visible to that tenant and its children (unless you use tagging to exclude).

Tenancy Providers::

Providers can be added at any level of tenancy. Once added, a provider is visible to any child or lower tenants, making it possible to easily separate resources that are owned or accessed by one group, and should not be available to other tenants. 
   

[[example-postgresql-configuration-file]]
=== Example PostgreSQL Configuration File

------
# -----------------------------
# PostgreSQL configuration file - MIQ Dedicated Appliance Configuration
# -----------------------------
#
# This file consists of lines of the form:
#
#   name = value
#
# (The "=" is optional.)  Whitespace may be used.  Comments are introduced with
# "#" anywhere on a line.  The complete list of parameter names and allowed
# values can be found in the PostgreSQL documentation.
#
# The commented-out settings shown in this file represent the default values.
# Re-commenting a setting is NOT sufficient to revert it to the default value;
# you need to reload the server.
#
# This file is read on server startup and when the server receives a SIGHUP
# signal.  If you edit the file on a running system, you have to SIGHUP the
# server for the changes to take effect, or use "pg_ctl reload".  Some
# parameters, which are marked below, require a server shutdown and restart to
# take effect.
#
# Any parameter can also be given as a command-line option to the server, e.g.,
# "postgres -c log_connections=on".  Some parameters can be changed at run time
# with the "SET" SQL command.
#
# Memory units:  kB = kilobytes        Time units:  ms  = milliseconds
#                MB = megabytes                     s   = seconds
#                GB = gigabytes                     min = minutes
#                                                   h   = hours
#                                                   d   = days


#------------------------------------------------------------------------------
# FILE LOCATIONS
#------------------------------------------------------------------------------

# The default values of these variables are driven from the -D command-line
# option or PGDATA environment variable, represented here as ConfigDir.

#data_directory = 'ConfigDir'		# use data in another directory
					# (change requires restart)
#hba_file = 'ConfigDir/pg_hba.conf'	# host-based authentication file
					# (change requires restart)
#ident_file = 'ConfigDir/pg_ident.conf'	# ident configuration file
					# (change requires restart)

# If external_pid_file is not explicitly set, no extra PID file is written.
#external_pid_file = '(none)'		# write an extra PID file
					# (change requires restart)


#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------

# - Connection Settings -

listen_addresses = '10.132.50.128'	# MIQ Value;
#listen_addresses = 'localhost'		# what IP address(es) to listen on;
					# comma-separated list of addresses;
					# defaults to 'localhost', '*' = all
					# (change requires restart)
#port = 5432				# (change requires restart)
max_connections = 1600			# MIQ Value increased
#max_connections = 100			# (change requires restart) Note:  Increasing max_connections costs ~400 bytes of shared memory per connection slot, plus lock space (see max_locks_per_transaction).
#superuser_reserved_connections = 3	# (change requires restart)
#unix_socket_directory = ''		# (change requires restart)
#unix_socket_group = ''			# (change requires restart)
#unix_socket_permissions = 0777		# begin with 0 to use octal notation
					# (change requires restart)
#bonjour = off				# advertise server via Bonjour
					# (change requires restart)
#bonjour_name = ''			# defaults to the computer name
					# (change requires restart)

# - Security and Authentication -

#authentication_timeout = 1min		# 1s-600s
#ssl = off				# (change requires restart)
#ssl_ciphers = 'ALL:!ADH:!LOW:!EXP:!MD5:@STRENGTH'	# allowed SSL ciphers
					# (change requires restart)
#ssl_renegotiation_limit = 512MB	# amount of data between renegotiations
#password_encryption = on
#db_user_namespace = off

# Kerberos and GSSAPI
#krb_server_keyfile = ''
#krb_srvname = 'postgres'		# (Kerberos only)
#krb_caseins_users = off

# - TCP Keepalives -
# see "man 7 tcp" for details

tcp_keepalives_idle = 3			# MIQ Value;
#tcp_keepalives_idle = 0		# TCP_KEEPIDLE, in seconds;
					# 0 selects the system default
tcp_keepalives_interval = 75		# MIQ Value;
#tcp_keepalives_interval = 0		# TCP_KEEPINTVL, in seconds;
					# 0 selects the system default
tcp_keepalives_count = 9		# MIQ Value;
#tcp_keepalives_count = 0		# TCP_KEEPCNT;
					# 0 selects the system default


#------------------------------------------------------------------------------
# RESOURCE USAGE (except WAL)
#------------------------------------------------------------------------------

# - Memory -

#shared_buffers = 128MB			# MIQ Value SHARED CONFIGURATION
shared_buffers = 4GB			# MIQ Value DEDICATED CONFIGURATION increased
#shared_buffers = 32MB			# min 128kB
					# (change requires restart)
#temp_buffers = 8MB			# min 800kB
#max_prepared_transactions = 0		# zero disables the feature
					# (change requires restart)
# Note:  Increasing max_prepared_transactions costs ~600 bytes of shared memory
# per transaction slot, plus lock space (see max_locks_per_transaction).
# It is not advisable to set max_prepared_transactions nonzero unless you
# actively intend to use prepared transactions.
#work_mem = 1MB				# min 64kB
#maintenance_work_mem = 16MB		# min 1MB
#max_stack_depth = 2MB			# min 100kB

# - Kernel Resource Usage -

#max_files_per_process = 1000		# min 25
					# (change requires restart)
#shared_preload_libraries = ''		# (change requires restart)

# - Cost-Based Vacuum Delay -

#vacuum_cost_delay = 0ms		# 0-100 milliseconds
#vacuum_cost_page_hit = 1		# 0-10000 credits
#vacuum_cost_page_miss = 10		# 0-10000 credits
#vacuum_cost_page_dirty = 20		# 0-10000 credits
#vacuum_cost_limit = 200		# 1-10000 credits

# - Background Writer -

#bgwriter_delay = 200ms			# 10-10000ms between rounds
#bgwriter_lru_maxpages = 100		# 0-1000 max buffers written/round
#bgwriter_lru_multiplier = 2.0		# 0-10.0 multipler on buffers scanned/round

# - Asynchronous Behavior -

#effective_io_concurrency = 1		# 1-1000. 0 disables prefetching


#------------------------------------------------------------------------------
# WRITE AHEAD LOG
#------------------------------------------------------------------------------

# - Settings -

#wal_level = minimal			# minimal, archive, or hot_standby
					# (change requires restart)
#fsync = on				# turns forced synchronization on or off
#synchronous_commit = on		# synchronization level; on, off, or local
#wal_sync_method = fsync		# the default is the first option
					# supported by the operating system:
					#   open_datasync
					#   fdatasync (default on Linux)
					#   fsync
					#   fsync_writethrough
					#   open_sync
#full_page_writes = on			# recover from partial page writes
wal_buffers = 16MB			# MIQ Value;
#wal_buffers = -1			# min 32kB, -1 sets based on shared_buffers
					# (change requires restart)
#wal_writer_delay = 200ms		# 1-10000 milliseconds

#commit_delay = 0			# range 0-100000, in microseconds
#commit_siblings = 5			# range 1-1000

# - Checkpoints -

checkpoint_segments = 15		# MIQ Value;
#checkpoint_segments = 3		# in logfile segments, min 1, 16MB each
#checkpoint_timeout = 5min		# range 30s-1h
checkpoint_completion_target = 0.9	# MIQ Value;
#checkpoint_completion_target = 0.5	# checkpoint target duration, 0.0 - 1.0
#checkpoint_warning = 30s		# 0 disables

# - Archiving -

#archive_mode = off		# allows archiving to be done
				# (change requires restart)
#archive_command = ''		# command to use to archive a logfile segment
#archive_timeout = 0		# force a logfile segment switch after this
				# number of seconds; 0 disables


#------------------------------------------------------------------------------
# REPLICATION
#------------------------------------------------------------------------------

# - Master Server -

# These settings are ignored on a standby server

#max_wal_senders = 0		# max number of walsender processes
				# (change requires restart)
#wal_sender_delay = 1s		# walsender cycle time, 1-10000 milliseconds
#wal_keep_segments = 0		# in logfile segments, 16MB each; 0 disables
#vacuum_defer_cleanup_age = 0	# number of xacts by which cleanup is delayed
#replication_timeout = 60s	# in milliseconds; 0 disables
#synchronous_standby_names = ''	# standby servers that provide sync rep
				# comma-separated list of application_name
				# from standby(s); '*' = all

# - Standby Servers -

# These settings are ignored on a master server

#hot_standby = off			# "on" allows queries during recovery
					# (change requires restart)
#max_standby_archive_delay = 30s	# max delay before canceling queries
					# when reading WAL from archive;
					# -1 allows indefinite delay
#max_standby_streaming_delay = 30s	# max delay before canceling queries
					# when reading streaming WAL;
					# -1 allows indefinite delay
#wal_receiver_status_interval = 10s	# send replies at least this often
					# 0 disables
#hot_standby_feedback = off		# send info from standby to prevent
					# query conflicts


#------------------------------------------------------------------------------
# QUERY TUNING
#------------------------------------------------------------------------------

# - Planner Method Configuration -

#enable_bitmapscan = on
#enable_hashagg = on
#enable_hashjoin = on
#enable_indexscan = on
#enable_material = on
#enable_mergejoin = on
#enable_nestloop = on
#enable_seqscan = on
#enable_sort = on
#enable_tidscan = on

# - Planner Cost Constants -

#seq_page_cost = 1.0			# measured on an arbitrary scale
#random_page_cost = 4.0			# same scale as above
#cpu_tuple_cost = 0.01			# same scale as above
#cpu_index_tuple_cost = 0.005		# same scale as above
#cpu_operator_cost = 0.0025		# same scale as above
#effective_cache_size = 128MB

# - Genetic Query Optimizer -

#geqo = on
#geqo_threshold = 12
#geqo_effort = 5			# range 1-10
#geqo_pool_size = 0			# selects default based on effort
#geqo_generations = 0			# selects default based on effort
#geqo_selection_bias = 2.0		# range 1.5-2.0
#geqo_seed = 0.0			# range 0.0-1.0

# - Other Planner Options -

#default_statistics_target = 100	# range 1-10000
#constraint_exclusion = partition	# on, off, or partition
#cursor_tuple_fraction = 0.1		# range 0.0-1.0
#from_collapse_limit = 8
#join_collapse_limit = 8		# 1 disables collapsing of explicit
					# JOIN clauses


#------------------------------------------------------------------------------
# ERROR REPORTING AND LOGGING
#------------------------------------------------------------------------------

# - Where to Log -


log_destination = 'stderr'		# Valid values are combinations of
					# stderr, csvlog, syslog, and eventlog,
					# depending on platform.  csvlog
					# requires logging_collector to be on.

# This is used when logging to stderr:
logging_collector = on		# Enable capturing of stderr and csvlog
					# into log files. Required to be on for
					# csvlogs.
					# (change requires restart)

# These are only used if logging_collector is on:
log_directory = '/www/postgres/log'	# Customer specific setting
#log_directory = 'pg_log'		# directory where log files are written,
					# can be absolute or relative to PGDATA
log_filename = 'postgresql-%Y-%m-%d.log'        # log file name pattern,
					# can include strftime() escapes
log_file_mode = 0644                    # creation mode for log files,
					# begin with 0 to use octal notation
log_truncate_on_rotation = on           # If on, an existing log file with the
					# same name as the new log file will be
					# truncated rather than appended to.
					# But such truncation only occurs on
					# time-driven rotation, not on restarts
					# or size-driven rotation.  Default is
					# off, meaning append to existing files
					# in all cases.
log_rotation_age = 1d                   # Automatic rotation of logfiles will
					# happen after that time.  0 disables.
log_rotation_size = 0                   # Automatic rotation of logfiles will
					# happen after that much log output.
					# 0 disables.

# These are relevant when logging to syslog:
#syslog_facility = 'LOCAL0'
#syslog_ident = 'postgres'

#silent_mode = off			# Run server silently.
					# DO NOT USE without syslog or
					# logging_collector
					# (change requires restart)


# - When to Log -

#client_min_messages = notice		# values in order of decreasing detail:
					#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
					#   log
					#   notice
					#   warning
					#   error

#log_min_messages = warning		# values in order of decreasing detail:
					#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
					#   info
					#   notice
					#   warning
					#   error
					#   log
					#   fatal
					#   panic

#log_min_error_statement = error	# values in order of decreasing detail:
				 	#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
				 	#   info
					#   notice
					#   warning
					#   error
					#   log
					#   fatal
					#   panic (effectively off)

log_min_duration_statement = 5000	# MIQ Value- ANY statement > 5 seconds
#log_min_duration_statement = -1	# -1 is disabled, 0 logs all statements
					# and their durations, > 0 logs only
					# statements running at least this number
					# of milliseconds


# - What to Log -

#debug_print_parse = off
#debug_print_rewritten = off
#debug_print_plan = off
#debug_pretty_print = on
#log_checkpoints = off
#log_connections = off
#log_disconnections = off
#log_duration = off
#log_error_verbosity = default		# terse, default, or verbose messages
#log_hostname = off
log_line_prefix = '%t:%r:%c:%u@%d:[%p]:'	# MIQ Value;
#log_line_prefix = ''			# special values:
					#   %a = application name
					#   %u = user name
					#   %d = database name
					#   %r = remote host and port
					#   %h = remote host
					#   %p = process ID
					#   %t = timestamp without milliseconds
					#   %m = timestamp with milliseconds
					#   %i = command tag
					#   %e = SQL state
					#   %c = session ID
					#   %l = session line number
					#   %s = session start timestamp
					#   %v = virtual transaction ID
					#   %x = transaction ID (0 if none)
					#   %q = stop here in non-session
					#        processes
					#   %% = '%'
					# e.g. '<%u%%%d> '
log_lock_waits = on			# MIQ Value - used to track possible deadlock issues
#log_lock_waits = off			# log lock waits >= deadlock_timeout
#log_statement = 'none'			# none, ddl, mod, all
#log_temp_files = -1			# log temporary files equal or larger
					# than the specified size in kilobytes;
					# -1 disables, 0 logs all temp files
#log_timezone = '(defaults to server environment setting)'


#------------------------------------------------------------------------------
# RUNTIME STATISTICS
#------------------------------------------------------------------------------

# - Query/Index Statistics Collector -

#track_activities = on
track_counts = on			# MIQ Value;
#track_counts = on
#track_functions = none			# none, pl, all
#track_activity_query_size = 1024 	# (change requires restart)
#update_process_title = on
#stats_temp_directory = 'pg_stat_tmp'


# - Statistics Monitoring -

#log_parser_stats = off
#log_planner_stats = off
#log_executor_stats = off
#log_statement_stats = off


#------------------------------------------------------------------------------
# AUTOVACUUM PARAMETERS
#------------------------------------------------------------------------------

autovacuum = on				# MIQ Value;
#autovacuum = on			# Enable autovacuum subprocess?  'on'
					# requires track_counts to also be on.
log_autovacuum_min_duration = 0		# MIQ Value;
#log_autovacuum_min_duration = -1	# -1 disables, 0 logs all actions and
					# their durations, > 0 logs only
					# actions running at least this number
					# of milliseconds.
autovacuum_max_workers = 1		# max number of autovacuum subprocesses
					# (change requires restart)
autovacuum_naptime = 30min		# MIQ Value;
#autovacuum_naptime = 1min		# time between autovacuum runs
autovacuum_vacuum_threshold = 500	# MIQ Value;
#autovacuum_vacuum_threshold = 50	# min number of row updates before
					# vacuum
autovacuum_analyze_threshold = 500	# MIQ Value;
#autovacuum_analyze_threshold = 50	# min number of row updates before
					# analyze
autovacuum_vacuum_scale_factor = 0.05	# MIQ Value;
#autovacuum_vacuum_scale_factor = 0.2	# fraction of table size before vacuum
#autovacuum_analyze_scale_factor = 0.1	# fraction of table size before analyze
#autovacuum_freeze_max_age = 200000000	# maximum XID age before forced vacuum
					# (change requires restart)
#autovacuum_vacuum_cost_delay = 20ms	# default vacuum cost delay for
					# autovacuum, in milliseconds;
					# -1 means use vacuum_cost_delay
#autovacuum_vacuum_cost_limit = -1	# default vacuum cost limit for
					# autovacuum, -1 means use
					# vacuum_cost_limit


#------------------------------------------------------------------------------
# CLIENT CONNECTION DEFAULTS
#------------------------------------------------------------------------------

# - Statement Behavior -

#search_path = '"$user",public'		# schema names
#default_tablespace = ''		# a tablespace name, '' uses the default
#temp_tablespaces = ''			# a list of tablespace names, '' uses
					# only default tablespace
#check_function_bodies = on
#default_transaction_isolation = 'read committed'
#default_transaction_read_only = off
#default_transaction_deferrable = off
#session_replication_role = 'origin'
#statement_timeout = 0			# in milliseconds, 0 is disabled
#statement_timeout = 43200000			# MIQ statment timeout of 12 hours as a default
#vacuum_freeze_min_age = 50000000
#vacuum_freeze_table_age = 150000000
#bytea_output = 'hex'			# hex, escape
#xmlbinary = 'base64'
#xmloption = 'content'

# - Locale and Formatting -

datestyle = 'iso, mdy'
#intervalstyle = 'postgres'
#timezone = '(defaults to server environment setting)'
#timezone_abbreviations = 'Default'     # Select the set of available time zone
					# abbreviations.  Currently, there are
					#   Default
					#   Australia
					#   India
					# You can create your own file in
					# share/timezonesets/.
#extra_float_digits = 0			# min -15, max 3
#client_encoding = sql_ascii		# actually, defaults to database
					# encoding

# These settings are initialized by initdb, but they can be changed.
lc_messages = 'en_US.UTF-8'			# locale for system error message
					# strings
lc_monetary = 'en_US.UTF-8'			# locale for monetary formatting
lc_numeric = 'en_US.UTF-8'			# locale for number formatting
lc_time = 'en_US.UTF-8'				# locale for time formatting

# default configuration for text search
default_text_search_config = 'pg_catalog.english'

# - Other Defaults -

#dynamic_library_path = '$libdir'
#local_preload_libraries = ''


#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

deadlock_timeout = 5s			# MIQ Value - one second is too low, 5 seconds is more "interesting"
#deadlock_timeout = 1s
#max_locks_per_transaction = 64		# min 10
					# (change requires restart)
# Note:  Each lock table slot uses ~270 bytes of shared memory, and there are
# max_locks_per_transaction * (max_connections + max_prepared_transactions)
# lock table slots.
#max_pred_locks_per_transaction = 64	# min 10
					# (change requires restart)

#------------------------------------------------------------------------------
# VERSION/PLATFORM COMPATIBILITY
#------------------------------------------------------------------------------

# - Previous PostgreSQL Versions -

#array_nulls = on
#backslash_quote = safe_encoding	# on, off, or safe_encoding
#default_with_oids = off
escape_string_warning = off		# MIQ Value no sure why this is enabled
#escape_string_warning = on
#lo_compat_privileges = off
#quote_all_identifiers = off
#sql_inheritance = on
standard_conforming_strings = off	# MIQ Value not sure why this is enabled
#standard_conforming_strings = on
#synchronize_seqscans = on

# - Other Platforms and Clients -

#transform_null_equals = off


#------------------------------------------------------------------------------
# ERROR HANDLING
#------------------------------------------------------------------------------

#exit_on_error = off				# terminate session on any error?
#restart_after_crash = on			# reinitialize after backend crash?


#------------------------------------------------------------------------------
# CUSTOMIZED OPTIONS
#------------------------------------------------------------------------------

#custom_variable_classes = ''		# list of custom variable class names
------


[[load-balancer]]
=== Using a Load Balancer

Deploying several {product-title_short} appliances with a load balancer can be useful for performance.

However, running several appliances behind a load balancer can cause login issues from the Self Service user interface because `memcached`, the service storing the session in memory, is not shared between the appliances. To prevent this, configure your environment using the steps below to run the `memcached` service on one appliance and have it shared with the other appliances.

[IMPORTANT]
====
When using this configuration, always start the appliance that owns `memcached` first, and ensure that `memcached` is running before starting the additional appliances. Starting another appliance before the `memcached` appliance may result in starting or login issues.
====

The following example shows configuration on two appliances, `appliance1` and `appliance2`:

. On `appliance1`, open the 11211 port in the firewall:
+
----
# firewall-cmd --add-port=11211/tcp --permanent
# firewall-cmd --reload
----
+
. On `appliance1`, configure the server's advanced settings by navigating to the settings menu, selecting *Configuration*, then the *Advanced* tab:
+
----
:session:
  :memcache_server: 127.0.0.1:11211
  :memcache_server_opts: "-l 0.0.0.0 -I 1M"
----
+
This configures `memcached` to run on `appliance1`, but listen to all servers (-l 0.0.0.0). The `memcache_server` line, which specifies where it connects to, remains set as itself (127.0.0.1).
+
. Click *Save*.
. Restart `appliance1`:
+
----
# systemctl restart appliance1
----

. Configure `appliance2` to point to `appliance1` by specifying the IP address for `appliance1` in the `memcache_server` line. Configure this in the server's advanced settings by navigating to the settings menu, selecting *Configuration*, then the *Advanced* tab:
+
----
:session:
  :memcache_server: <appliance1>:11211        
  :memcache_server_opts: "-l 127.0.0.1 -I 1M"   
----
+
. Click *Save*.
. Restart `appliance2`:
+
----
# systemctl restart appliance2
----

You can then get an API token from `appliance1`, and use it to access the API from `appliance2`. See https://access.redhat.com/documentation/en-us/red_hat_cloudforms/4.2/html-single/red_hat_cloudforms_rest_api/#using-authentication-tokens[Using Authentication Tokens] in the _REST API_ guide for instructions.

The shared `memcached` service now runs only on `appliance1`, and any other appliance accesses `memcached` from that appliance. Configure additional appliances with the steps for `appliance2`.


